{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a Spark session to start...\n",
      "Spark Initialization Done! ApplicationId = app-20200116111721-0003\n",
      "KERNEL_ID = b23b2794-3197-4c83-95b8-c0aa18a7e406\n",
      "conda\n",
      "dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\n",
      "dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar.1\n",
      "iris.txt\n",
      "iris.txt.1\n",
      "jre-8u241-linux-x64.tar.gz\n",
      "jre1.8.0_241\n",
      "logs\n",
      "spark-events\n",
      "user-libs\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/SkymindIO/dsx/releases/download/1.0/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-16 11:18:34--  https://raw.githubusercontent.com/SkymindIO/dsx/master/iris.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2850 (2.8K) [text/plain]\r\n",
      "Saving to: 'iris.txt'\r\n",
      "\r\n",
      "100%[======================================>] 2,850       --.-K/s   in 0s      \r\n",
      "\r\n",
      "2020-01-16 11:18:34 (62.8 MB/s) - 'iris.txt' saved [2850/2850]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/SkymindIO/dsx/master/iris.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda\t\t\t\t\t\t\t  jre1.8.0_241\r\n",
      "dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\t  logs\r\n",
      "dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar.1  spark-events\r\n",
      "iris.txt\t\t\t\t\t\t  user-libs\r\n",
      "jre-8u241-linux-x64.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://download.oracle.com/otn/java/jdk/8u241-b07/1f5b5a70bf22433b84d0e960903adac8/jre-8u241-linux-x64.tar.gz?AuthParam=1579172900_be1cd02cb34bfbd0750c95773742ad21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mv jre-8u241-linux-x64.tar.gz\\?AuthParam\\=1579172900_be1cd02cb34bfbd0750c95773742ad21 jre-8u241-linux-x64.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar -xzf jre-8u241-linux-x64.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda\t\t\t\t\t\t\t  jre1.8.0_241\r\n",
      "dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\t  logs\r\n",
      "dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar.1  spark-events\r\n",
      "iris.txt\t\t\t\t\t\t  user-libs\r\n",
      "jre-8u241-linux-x64.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat iris.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [main] INFO org.nd4j.linalg.factory.Nd4jBackend  - Loaded [CpuBackend] backend\n",
      "109 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/cldrdata.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/localedata.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/zipfs.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/nashorn.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/dnsns.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/jfxrt.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/sunjce_provider.jar\n",
      "file:/home/spark/shared/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/jaccess.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/sunpkcs11.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/sunec.jar\n",
      "957 [main] INFO org.reflections.Reflections  - Reflections took 825 ms to scan 11 urls, producing 133697 keys and 147247 values \n",
      "1554 [main] INFO org.nd4j.nativeblas.NativeOpsHolder  - Number of threads used for NativeOps: 16\n",
      "1557 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\n",
      "jar:file:/home/spark/shared/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar!/\n",
      "1984 [main] INFO org.reflections.Reflections  - Reflections took 427 ms to scan 1 urls, producing 31 keys and 227 values \n",
      "2623 [main] INFO org.nd4j.nativeblas.Nd4jBlas  - Number of threads used for BLAS: 16\n",
      "2653 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Backend used: [CPU]; OS: [Linux]\n",
      "2653 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Cores: [3]; Memory: [1.3GB];\n",
      "2653 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Blas vendor: [OPENBLAS]\n",
      "2682 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\n",
      "jar:file:/home/spark/shared/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar!/\n",
      "3251 [main] INFO org.reflections.Reflections  - Reflections took 569 ms to scan 1 urls, producing 421 keys and 1666 values \n",
      "3536 [main] INFO skymind.dsx.IrisClassifier  - Build model....\n",
      "3843 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/cldrdata.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/localedata.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/zipfs.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/nashorn.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/dnsns.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/jfxrt.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/sunjce_provider.jar\n",
      "file:/home/spark/shared/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/jaccess.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/sunpkcs11.jar\n",
      "file:/home/spark/shared/jre1.8.0_241/lib/ext/sunec.jar\n",
      "10577 [main] INFO org.reflections.Reflections  - Reflections took 6732 ms to scan 11 urls, producing 7023 keys and 48632 values \n",
      "10617 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.modelimport.keras.preprocessors.TensorFlowCnnToFeedForwardPreProcessor as subtype of org.deeplearning4j.nn.conf.InputPreProcessor\n",
      "10617 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.PoolHelperVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n",
      "10617 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ReshapeVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n",
      "10618 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ShiftVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n",
      "10618 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.layers.CenterLossOutputLayer as subtype of org.deeplearning4j.nn.conf.layers.Layer\n",
      "10622 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.modelimport.keras.preprocessors.TensorFlowCnnToFeedForwardPreProcessor as subtype of org.deeplearning4j.nn.conf.InputPreProcessor\n",
      "10622 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.PoolHelperVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n",
      "10622 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ReshapeVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n",
      "10622 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ShiftVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n",
      "10622 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.layers.CenterLossOutputLayer as subtype of org.deeplearning4j.nn.conf.layers.Layer\n",
      "10653 [main] INFO org.deeplearning4j.nn.multilayer.MultiLayerNetwork  - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n",
      "10952 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 0 is 1.4340900930446707\n",
      "25539 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 100 is 0.341702591272909\n",
      "38898 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 200 is 0.13662269202080998\n",
      "52501 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 300 is 0.08756063698026953\n",
      "65836 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 400 is 0.06747824528976375\n",
      "78876 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 500 is 0.05638096149786133\n",
      "91300 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 600 is 0.049298375429255435\n",
      "104556 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 700 is 0.04436464647079826\n",
      "118456 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 800 is 0.040710264893328185\n",
      "132615 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 900 is 0.0378762315382777\n",
      "144297 [main] INFO skymind.dsx.IrisClassifier  - \n",
      "Examples labeled as 0 classified by model as 0: 21 times\n",
      "Examples labeled as 1 classified by model as 1: 17 times\n",
      "Examples labeled as 2 classified by model as 1: 1 times\n",
      "Examples labeled as 2 classified by model as 2: 14 times\n",
      "\n",
      "\n",
      "==========================Scores========================================\n",
      " # of classes:    3\n",
      " Accuracy:        0.9811\n",
      " Precision:       0.9815\n",
      " Recall:          0.9778\n",
      " F1 Score:        0.9790\n",
      "Precision, recall & F1: macro-averaged (equally weighted avg. of 3 classes)\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "!jre1.8.0_241/bin/java -cp dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar skymind.dsx.IrisClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beeline\t\t      pyspark\t       spark-class2.cmd  spark-submit\r\n",
      "beeline.cmd\t      pyspark.cmd      spark-shell\t spark-submit.cmd\r\n",
      "docker-image-tool.sh  pyspark2.cmd     spark-shell.cmd\t spark-submit2.cmd\r\n",
      "find-spark-home       run-example      spark-shell2.cmd  sparkR\r\n",
      "find-spark-home.cmd   run-example.cmd  spark-sql\t sparkR.cmd\r\n",
      "load-spark-env.cmd    spark-class      spark-sql.cmd\t sparkR2.cmd\r\n",
      "load-spark-env.sh     spark-class.cmd  spark-sql2.cmd\r\n"
     ]
    }
   ],
   "source": [
    "!ls $SPARK_HOME/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/opt/ibm/spark/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/opt/ibm/image-libs/spark2/tika-app-1.14.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "20/01/16 11:39:42 [WARN] o.a.h.u.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "20/01/16 11:39:43 [INFO] o.n.l.f.Nd4jBackend - Loaded [CpuBackend] backend\n",
      "567 [main] INFO org.nd4j.linalg.factory.Nd4jBackend  - Loaded [CpuBackend] backend\n",
      "20/01/16 11:39:43 [WARN] o.r.Reflections - could not create Dir using directory from url file:/home/spark/shared/user-libs/common/*. skipping.\n",
      "java.lang.NullPointerException\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "1357 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/home/spark/shared/user-libs/common/*. skipping.\n",
      "java.lang.NullPointerException\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "20/01/16 11:39:43 [WARN] o.r.Reflections - could not create Vfs.Dir from url. ignoring the exception and continuing\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/spark/shared/user-libs/common/*]\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "1361 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/spark/shared/user-libs/common/*]\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "20/01/16 11:39:43 [WARN] o.r.Reflections - could not create Dir using directory from url file:/opt/ibm/image-libs/common/*. skipping.\r\n",
      "java.lang.NullPointerException\r\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "1429 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/opt/ibm/image-libs/common/*. skipping.\r\n",
      "java.lang.NullPointerException\r\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "20/01/16 11:39:43 [WARN] o.r.Reflections - could not create Vfs.Dir from url. ignoring the exception and continuing\r\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/opt/ibm/image-libs/common/*]\r\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "1432 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/opt/ibm/image-libs/common/*]\r\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "20/01/16 11:39:44 [WARN] o.r.Reflections - could not create Dir using directory from url file:/home/spark/shared/user-libs/connectors/*. skipping.\r\n",
      "java.lang.NullPointerException\r\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "2417 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/home/spark/shared/user-libs/connectors/*. skipping.\r\n",
      "java.lang.NullPointerException\r\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "20/01/16 11:39:44 [WARN] o.r.Reflections - could not create Vfs.Dir from url. ignoring the exception and continuing\r\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/spark/shared/user-libs/connectors/*]\r\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "2422 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/spark/shared/user-libs/connectors/*]\r\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "20/01/16 11:39:45 [WARN] o.r.Reflections - could not create Dir using directory from url file:/home/spark/shared/user-libs/spark2/*. skipping.\r\n",
      "java.lang.NullPointerException\r\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "3148 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/home/spark/shared/user-libs/spark2/*. skipping.\r\n",
      "java.lang.NullPointerException\r\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "20/01/16 11:39:45 [WARN] o.r.Reflections - could not create Vfs.Dir from url. ignoring the exception and continuing\r\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/spark/shared/user-libs/spark2/*]\r\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "3150 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/spark/shared/user-libs/spark2/*]\r\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n",
      "\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n",
      "\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n",
      "\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "20/01/16 11:39:45 [INFO] o.r.Reflections - Reflections took 2600 ms to scan 360 urls, producing 278536 keys and 363778 values \n",
      "3197 [main] INFO org.reflections.Reflections  - Reflections took 2600 ms to scan 360 urls, producing 278536 keys and 363778 values \n",
      "20/01/16 11:39:46 [INFO] o.n.n.NativeOpsHolder - Number of threads used for NativeOps: 16\n",
      "3800 [main] INFO org.nd4j.nativeblas.NativeOpsHolder  - Number of threads used for NativeOps: 16\n",
      "20/01/16 11:39:46 [INFO] o.r.Reflections - Reflections took 401 ms to scan 1 urls, producing 31 keys and 227 values \n",
      "4204 [main] INFO org.reflections.Reflections  - Reflections took 401 ms to scan 1 urls, producing 31 keys and 227 values \n",
      "20/01/16 11:39:46 [INFO] o.n.n.Nd4jBlas - Number of threads used for BLAS: 16\n",
      "4445 [main] INFO org.nd4j.nativeblas.Nd4jBlas  - Number of threads used for BLAS: 16\n",
      "20/01/16 11:39:46 [INFO] o.n.l.a.o.e.DefaultOpExecutioner - Backend used: [CPU]; OS: [Linux]\n",
      "4446 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Backend used: [CPU]; OS: [Linux]\n",
      "20/01/16 11:39:46 [INFO] o.n.l.a.o.e.DefaultOpExecutioner - Cores: [3]; Memory: [4.0GB];\n",
      "4447 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Cores: [3]; Memory: [4.0GB];\n",
      "20/01/16 11:39:46 [INFO] o.n.l.a.o.e.DefaultOpExecutioner - Blas vendor: [OPENBLAS]\n",
      "4447 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Blas vendor: [OPENBLAS]\n",
      "20/01/16 11:39:47 [INFO] o.r.Reflections - Reflections took 526 ms to scan 1 urls, producing 421 keys and 1666 values \n",
      "5017 [main] INFO org.reflections.Reflections  - Reflections took 526 ms to scan 1 urls, producing 421 keys and 1666 values \n",
      "20/01/16 11:39:47 [INFO] s.d.IrisClassifier - Build model....\n",
      "5321 [main] INFO skymind.dsx.IrisClassifier  - Build model....\n",
      "20/01/16 11:39:56 [WARN] o.r.Reflections - could not create Dir using directory from url file:/home/spark/shared/user-libs/common/*. skipping.\n",
      "java.lang.NullPointerException\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "13826 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/home/spark/shared/user-libs/common/*. skipping.\n",
      "java.lang.NullPointerException\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "20/01/16 11:39:56 [WARN] o.r.Reflections - could not create Vfs.Dir from url. ignoring the exception and continuing\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/spark/shared/user-libs/common/*]\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "13827 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/spark/shared/user-libs/common/*]\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "20/01/16 11:39:57 [WARN] o.r.Reflections - could not create Dir using directory from url file:/opt/ibm/image-libs/common/*. skipping.\r\n",
      "java.lang.NullPointerException\r\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "14786 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/opt/ibm/image-libs/common/*. skipping.\r\n",
      "java.lang.NullPointerException\r\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "20/01/16 11:39:57 [WARN] o.r.Reflections - could not create Vfs.Dir from url. ignoring the exception and continuing\r\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/opt/ibm/image-libs/common/*]\r\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "14788 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/opt/ibm/image-libs/common/*]\r\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "20/01/16 11:40:10 [WARN] o.r.Reflections - could not create Dir using directory from url file:/home/spark/shared/user-libs/connectors/*. skipping.\n",
      "java.lang.NullPointerException\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "27838 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/home/spark/shared/user-libs/connectors/*. skipping.\n",
      "java.lang.NullPointerException\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "20/01/16 11:40:10 [WARN] o.r.Reflections - could not create Vfs.Dir from url. ignoring the exception and continuing\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/spark/shared/user-libs/connectors/*]\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "27840 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/spark/shared/user-libs/connectors/*]\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "20/01/16 11:40:16 [WARN] o.r.Reflections - could not create Dir using directory from url file:/home/spark/shared/user-libs/spark2/*. skipping.\r\n",
      "java.lang.NullPointerException\r\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "33781 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/home/spark/shared/user-libs/spark2/*. skipping.\r\n",
      "java.lang.NullPointerException\r\n",
      "\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "20/01/16 11:40:16 [WARN] o.r.Reflections - could not create Vfs.Dir from url. ignoring the exception and continuing\r\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/spark/shared/user-libs/spark2/*]\r\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "33782 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\n",
      "org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/spark/shared/user-libs/spark2/*]\r\n",
      "either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n",
      "\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n",
      "\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n",
      "\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n",
      "\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n",
      "\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "20/01/16 11:40:17 [INFO] o.r.Reflections - Reflections took 28949 ms to scan 348 urls, producing 19016 keys and 125919 values \n",
      "34633 [main] INFO org.reflections.Reflections  - Reflections took 28949 ms to scan 348 urls, producing 19016 keys and 125919 values \n",
      "20/01/16 11:40:17 [INFO] o.d.n.m.MultiLayerNetwork - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n",
      "34788 [main] INFO org.deeplearning4j.nn.multilayer.MultiLayerNetwork  - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n",
      "20/01/16 11:40:17 [INFO] o.d.o.l.ScoreIterationListener - Score at iteration 0 is 1.4342950642008403\n",
      "35216 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 0 is 1.4342950642008403\n",
      "20/01/16 11:40:35 [INFO] o.d.o.l.ScoreIterationListener - Score at iteration 100 is 0.3578075743832967\n",
      "53303 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 100 is 0.3578075743832967\n",
      "20/01/16 11:40:53 [INFO] o.d.o.l.ScoreIterationListener - Score at iteration 200 is 0.14895401182238668\n",
      "70841 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 200 is 0.14895401182238668\n",
      "20/01/16 11:41:08 [INFO] o.d.o.l.ScoreIterationListener - Score at iteration 300 is 0.09124742249317247\n",
      "85623 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 300 is 0.09124742249317247\n",
      "20/01/16 11:41:20 [INFO] o.d.o.l.ScoreIterationListener - Score at iteration 400 is 0.06801207995237059\n",
      "97904 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 400 is 0.06801207995237059\n",
      "20/01/16 11:41:33 [INFO] o.d.o.l.ScoreIterationListener - Score at iteration 500 is 0.055731759051966964\n",
      "111464 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 500 is 0.055731759051966964\n",
      "20/01/16 11:41:48 [INFO] o.d.o.l.ScoreIterationListener - Score at iteration 600 is 0.04826474146553357\n",
      "125782 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 600 is 0.04826474146553357\n",
      "20/01/16 11:42:01 [INFO] o.d.o.l.ScoreIterationListener - Score at iteration 700 is 0.04326185591090037\n",
      "138864 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 700 is 0.04326185591090037\n",
      "20/01/16 11:42:15 [INFO] o.d.o.l.ScoreIterationListener - Score at iteration 800 is 0.039658083272747224\n",
      "152883 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 800 is 0.039658083272747224\n",
      "20/01/16 11:42:26 [INFO] o.d.o.l.ScoreIterationListener - Score at iteration 900 is 0.03691751818948894\n",
      "164303 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 900 is 0.03691751818948894\n",
      "20/01/16 11:42:41 [INFO] s.d.IrisClassifier - \n",
      "Examples labeled as 0 classified by model as 0: 19 times\n",
      "Examples labeled as 1 classified by model as 1: 20 times\n",
      "Examples labeled as 2 classified by model as 1: 2 times\n",
      "Examples labeled as 2 classified by model as 2: 12 times\n",
      "\n",
      "\n",
      "==========================Scores========================================\n",
      " # of classes:    3\n",
      " Accuracy:        0.9623\n",
      " Precision:       0.9697\n",
      " Recall:          0.9524\n",
      " F1 Score:        0.9585\n",
      "Precision, recall & F1: macro-averaged (equally weighted avg. of 3 classes)\n",
      "========================================================================\n",
      "179315 [main] INFO skymind.dsx.IrisClassifier  - \n",
      "Examples labeled as 0 classified by model as 0: 19 times\n",
      "Examples labeled as 1 classified by model as 1: 20 times\n",
      "Examples labeled as 2 classified by model as 1: 2 times\n",
      "Examples labeled as 2 classified by model as 2: 12 times\n",
      "\n",
      "\n",
      "==========================Scores========================================\n",
      " # of classes:    3\n",
      " Accuracy:        0.9623\n",
      " Precision:       0.9697\n",
      " Recall:          0.9524\n",
      " F1 Score:        0.9585\n",
      "Precision, recall & F1: macro-averaged (equally weighted avg. of 3 classes)\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "!$SPARK_HOME/bin/spark-submit \\\n",
    "--class skymind.dsx.IrisClassifier \\\n",
    "--master local \\\n",
    "--files iris.txt \\\n",
    "dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org.apache.spark.deploy.master.Master running as process 109.  Stop it first.\r\n"
     ]
    }
   ],
   "source": [
    "#!/opt/ibm/spark/sbin/start-master.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
